HYPERPARAMETERS
================
batch_size = 16
block_size = 128
training_steps = 10000
eval_interval = 500
learning_rate = 1e-05
eval_iters = 20
n_embd = 256
n_head = 4
n_layer = 4
dropout = 0.2
max_new_tokens = 300
device = mps
tokenization_method = character
test_mode = False
use_lora = True
model_type = gpt2
training_data_source = sources/carolyn_hax_merged_cleaned.md
gpt2_model_name = gpt2
lora_rank = 16
lora_alpha = 32.0
lora_dropout = 0.0

OUTPUT
======
   üìå GPT-2 fine-tuning: Using lower LR (1e-5) and balanced context (128)
üöÄ FULL MODE: Using production hyperparameters (aggressively optimized for M4)
‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)
Device: mps
Model size: 4 layers, 256 embedding dims, 4 heads
ü§ñ Using GPT-2 model: gpt2
üîß Using LoRA for efficient fine-tuning
   LoRA rank: 16, alpha: 32.0, dropout: 0.0
üì• Loading gpt2 from HuggingFace...
   Applied LoRA to 49 layers
‚úÖ LoRA adapters applied (rank=16, alpha=32.0)
üìä Parameter Statistics:
   Model: gpt2
   Total parameters: 127,615,504
   Trainable (total): 3,175,696
   Frozen (base model): 124,439,808
   üí∞ LoRA savings: Training only 2.49% of parameters!
Model device: mps:0
‚úÖ Model successfully moved to Apple Silicon GPU (MPS)
‚ÑπÔ∏è  Using MPS without compilation (torch.compile disabled for MPS)
‚úÖ Optimizer initialized with 98 parameter groups (LoRA only)
üìà Learning rate schedule: 1000 warmup steps, 9000 decay steps
   LR range: 1.00e-06 ‚Üí 1.00e-05 ‚Üí 1.00e-06
Starting training for 10000 steps...
Batch size: 16, Block size: 128
Vocabulary size: 50,257 tokens
Checkpoints enabled: saving every 500 steps to checkpoints/
--------------------------------------------------
step 0/10000 (0.0%): train loss 9.5481, val loss 9.5103 | LR: 1.00e-06 | 16.7s (0.00 steps/sec)
step 25/10000 (0.2%) | 0.71 steps/sec | ETA: 234.5m
step 50/10000 (0.5%) | 0.92 steps/sec | ETA: 179.3m
step 75/10000 (0.8%) | 1.03 steps/sec | ETA: 160.4m
step 100/10000 (1.0%) | 1.10 steps/sec | ETA: 150.6m
step 125/10000 (1.2%) | 1.14 steps/sec | ETA: 144.7m
step 150/10000 (1.5%) | 1.17 steps/sec | ETA: 140.7m
step 175/10000 (1.8%) | 1.19 steps/sec | ETA: 137.5m
step 200/10000 (2.0%) | 1.21 steps/sec | ETA: 135.1m
step 225/10000 (2.2%) | 1.22 steps/sec | ETA: 133.1m
step 250/10000 (2.5%) | 1.24 steps/sec | ETA: 131.4m
step 275/10000 (2.8%) | 1.25 steps/sec | ETA: 129.9m
step 300/10000 (3.0%) | 1.26 steps/sec | ETA: 128.7m
step 325/10000 (3.2%) | 1.26 steps/sec | ETA: 127.6m
step 350/10000 (3.5%) | 1.27 steps/sec | ETA: 126.6m
step 375/10000 (3.8%) | 1.28 steps/sec | ETA: 125.7m
step 400/10000 (4.0%) | 1.28 steps/sec | ETA: 124.9m
step 425/10000 (4.2%) | 1.28 steps/sec | ETA: 124.3m
step 450/10000 (4.5%) | 1.29 steps/sec | ETA: 123.8m
step 475/10000 (4.8%) | 1.29 steps/sec | ETA: 123.4m
step 500/10000 (5.0%): train loss 7.4655, val loss 7.6023 | LR: 5.50e-06 | 407.6s (1.23 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step000500_11142025_093503.pt
step 525/10000 (5.2%) | 1.23 steps/sec | ETA: 128.8m
step 550/10000 (5.5%) | 1.23 steps/sec | ETA: 128.3m
step 575/10000 (5.8%) | 1.23 steps/sec | ETA: 127.8m
step 600/10000 (6.0%) | 1.23 steps/sec | ETA: 127.3m
step 625/10000 (6.2%) | 1.23 steps/sec | ETA: 126.8m
step 650/10000 (6.5%) | 1.23 steps/sec | ETA: 126.3m
step 675/10000 (6.8%) | 1.23 steps/sec | ETA: 126.0m
step 700/10000 (7.0%) | 1.23 steps/sec | ETA: 125.9m
step 725/10000 (7.2%) | 1.23 steps/sec | ETA: 125.7m
step 750/10000 (7.5%) | 1.23 steps/sec | ETA: 125.8m
step 775/10000 (7.8%) | 0.48 steps/sec | ETA: 317.3m
step 800/10000 (8.0%) | 0.49 steps/sec | ETA: 315.3m
step 825/10000 (8.2%) | 0.49 steps/sec | ETA: 312.7m
step 850/10000 (8.5%) | 0.49 steps/sec | ETA: 310.1m
step 875/10000 (8.8%) | 0.50 steps/sec | ETA: 307.0m
step 900/10000 (9.0%) | 0.50 steps/sec | ETA: 303.5m
step 925/10000 (9.2%) | 0.50 steps/sec | ETA: 300.1m
step 950/10000 (9.5%) | 0.51 steps/sec | ETA: 296.9m
step 975/10000 (9.8%) | 0.51 steps/sec | ETA: 294.0m
step 1000/10000 (10.0%): train loss 6.9436, val loss 7.3245 | LR: 1.00e-05 | 1973.9s (0.51 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step001000_11142025_100109.pt
step 1025/10000 (10.2%) | 0.51 steps/sec | ETA: 293.5m
step 1050/10000 (10.5%) | 0.51 steps/sec | ETA: 290.7m
step 1075/10000 (10.8%) | 0.52 steps/sec | ETA: 288.0m
step 1100/10000 (11.0%) | 0.52 steps/sec | ETA: 285.5m
step 1125/10000 (11.2%) | 0.52 steps/sec | ETA: 283.0m
step 1150/10000 (11.5%) | 0.53 steps/sec | ETA: 280.5m
step 1175/10000 (11.8%) | 0.53 steps/sec | ETA: 278.2m
step 1200/10000 (12.0%) | 0.53 steps/sec | ETA: 276.0m
step 1225/10000 (12.2%) | 0.53 steps/sec | ETA: 273.7m
step 1250/10000 (12.5%) | 0.54 steps/sec | ETA: 271.6m
step 1275/10000 (12.8%) | 0.54 steps/sec | ETA: 269.7m
step 1300/10000 (13.0%) | 0.54 steps/sec | ETA: 267.6m
step 1325/10000 (13.2%) | 0.54 steps/sec | ETA: 265.7m
step 1350/10000 (13.5%) | 0.55 steps/sec | ETA: 263.8m
step 1375/10000 (13.8%) | 0.55 steps/sec | ETA: 262.0m
step 1400/10000 (14.0%) | 0.55 steps/sec | ETA: 260.1m
step 1425/10000 (14.2%) | 0.55 steps/sec | ETA: 258.3m
step 1450/10000 (14.5%) | 0.56 steps/sec | ETA: 256.6m
step 1475/10000 (14.8%) | 0.56 steps/sec | ETA: 254.9m
step 1500/10000 (15.0%): train loss 6.6022, val loss 7.0417 | LR: 9.93e-06 | 2715.0s (0.55 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step001500_11142025_101330.pt
step 1525/10000 (15.2%) | 0.55 steps/sec | ETA: 254.9m
step 1550/10000 (15.5%) | 0.56 steps/sec | ETA: 253.2m
step 1575/10000 (15.8%) | 0.56 steps/sec | ETA: 251.6m
step 1600/10000 (16.0%) | 0.56 steps/sec | ETA: 250.1m
step 1625/10000 (16.2%) | 0.56 steps/sec | ETA: 248.4m
step 1650/10000 (16.5%) | 0.56 steps/sec | ETA: 246.9m
step 1675/10000 (16.8%) | 0.57 steps/sec | ETA: 244.4m
step 1700/10000 (17.0%) | 0.57 steps/sec | ETA: 241.7m
step 1725/10000 (17.2%) | 0.58 steps/sec | ETA: 239.0m
step 1750/10000 (17.5%) | 0.58 steps/sec | ETA: 236.3m
step 1775/10000 (17.8%) | 0.59 steps/sec | ETA: 233.6m
step 1800/10000 (18.0%) | 0.59 steps/sec | ETA: 231.1m
step 1825/10000 (18.2%) | 0.60 steps/sec | ETA: 228.6m
step 1850/10000 (18.5%) | 0.60 steps/sec | ETA: 226.2m
step 1875/10000 (18.8%) | 0.61 steps/sec | ETA: 223.8m
step 1900/10000 (19.0%) | 0.61 steps/sec | ETA: 221.5m
step 1925/10000 (19.2%) | 0.61 steps/sec | ETA: 219.3m
step 1950/10000 (19.5%) | 0.62 steps/sec | ETA: 217.1m
step 1975/10000 (19.8%) | 0.62 steps/sec | ETA: 215.1m
step 2000/10000 (20.0%): train loss 6.5787, val loss 7.0336 | LR: 9.73e-06 | 3216.0s (0.62 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step002000_11142025_102151.pt
step 2025/10000 (20.2%) | 0.63 steps/sec | ETA: 212.5m
step 2050/10000 (20.5%) | 0.63 steps/sec | ETA: 210.6m
step 2075/10000 (20.8%) | 0.63 steps/sec | ETA: 208.7m
step 2100/10000 (21.0%) | 0.64 steps/sec | ETA: 206.9m
step 2125/10000 (21.2%) | 0.64 steps/sec | ETA: 205.1m
step 2150/10000 (21.5%) | 0.64 steps/sec | ETA: 203.4m
step 2175/10000 (21.8%) | 0.65 steps/sec | ETA: 201.6m
step 2200/10000 (22.0%) | 0.65 steps/sec | ETA: 199.9m
step 2225/10000 (22.2%) | 0.65 steps/sec | ETA: 198.2m
step 2250/10000 (22.5%) | 0.66 steps/sec | ETA: 196.6m
step 2275/10000 (22.8%) | 0.66 steps/sec | ETA: 195.0m
step 2300/10000 (23.0%) | 0.66 steps/sec | ETA: 193.5m
step 2325/10000 (23.2%) | 0.67 steps/sec | ETA: 191.9m
step 2350/10000 (23.5%) | 0.67 steps/sec | ETA: 190.4m
step 2375/10000 (23.8%) | 0.67 steps/sec | ETA: 188.9m
step 2400/10000 (24.0%) | 0.68 steps/sec | ETA: 187.5m
step 2425/10000 (24.2%) | 0.68 steps/sec | ETA: 186.0m
step 2450/10000 (24.5%) | 0.68 steps/sec | ETA: 184.6m
step 2475/10000 (24.8%) | 0.54 steps/sec | ETA: 230.6m
step 2500/10000 (25.0%): train loss 6.8156, val loss 7.1941 | LR: 9.40e-06 | 4628.4s (0.54 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step002500_11142025_104524.pt
step 2525/10000 (25.2%) | 0.54 steps/sec | ETA: 230.3m
step 2550/10000 (25.5%) | 0.54 steps/sec | ETA: 229.0m
step 2575/10000 (25.8%) | 0.54 steps/sec | ETA: 227.7m
step 2600/10000 (26.0%) | 0.55 steps/sec | ETA: 225.9m
step 2625/10000 (26.2%) | 0.55 steps/sec | ETA: 223.9m
step 2650/10000 (26.5%) | 0.55 steps/sec | ETA: 221.9m
step 2675/10000 (26.8%) | 0.56 steps/sec | ETA: 220.0m
step 2700/10000 (27.0%) | 0.56 steps/sec | ETA: 218.0m
step 2725/10000 (27.3%) | 0.56 steps/sec | ETA: 216.1m
step 2750/10000 (27.5%) | 0.56 steps/sec | ETA: 214.2m
step 2775/10000 (27.8%) | 0.57 steps/sec | ETA: 212.4m
step 2800/10000 (28.0%) | 0.57 steps/sec | ETA: 210.5m
step 2825/10000 (28.2%) | 0.57 steps/sec | ETA: 208.8m
step 2850/10000 (28.5%) | 0.58 steps/sec | ETA: 207.0m
step 2875/10000 (28.7%) | 0.58 steps/sec | ETA: 205.3m
step 2900/10000 (29.0%) | 0.58 steps/sec | ETA: 203.7m
step 2925/10000 (29.2%) | 0.58 steps/sec | ETA: 202.0m
step 2950/10000 (29.5%) | 0.59 steps/sec | ETA: 200.4m
step 2975/10000 (29.8%) | 0.59 steps/sec | ETA: 198.9m
step 3000/10000 (30.0%): train loss 6.9255, val loss 7.3267 | LR: 8.95e-06 | 5092.8s (0.59 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step003000_11142025_105308.pt
step 3025/10000 (30.2%) | 0.59 steps/sec | ETA: 196.6m
step 3050/10000 (30.5%) | 0.59 steps/sec | ETA: 195.0m
step 3075/10000 (30.8%) | 0.60 steps/sec | ETA: 193.6m
step 3100/10000 (31.0%) | 0.60 steps/sec | ETA: 192.2m
step 3125/10000 (31.2%) | 0.60 steps/sec | ETA: 190.9m
step 3150/10000 (31.5%) | 0.60 steps/sec | ETA: 189.4m
step 3175/10000 (31.8%) | 0.60 steps/sec | ETA: 188.0m
step 3200/10000 (32.0%) | 0.61 steps/sec | ETA: 186.7m
step 3225/10000 (32.2%) | 0.61 steps/sec | ETA: 185.3m
step 3250/10000 (32.5%) | 0.61 steps/sec | ETA: 184.0m
step 3275/10000 (32.8%) | 0.61 steps/sec | ETA: 182.6m
step 3300/10000 (33.0%) | 0.62 steps/sec | ETA: 181.3m
step 3325/10000 (33.2%) | 0.62 steps/sec | ETA: 180.0m
step 3350/10000 (33.5%) | 0.62 steps/sec | ETA: 178.7m
step 3375/10000 (33.8%) | 0.62 steps/sec | ETA: 177.4m
step 3400/10000 (34.0%) | 0.62 steps/sec | ETA: 176.2m
step 3425/10000 (34.2%) | 0.54 steps/sec | ETA: 204.0m
step 3450/10000 (34.5%) | 0.54 steps/sec | ETA: 202.4m
step 3475/10000 (34.8%) | 0.54 steps/sec | ETA: 200.8m
step 3500/10000 (35.0%): train loss 7.0594, val loss 7.4342 | LR: 8.39e-06 | 6452.7s (0.54 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step003500_11142025_111548.pt
step 3525/10000 (35.2%) | 0.54 steps/sec | ETA: 198.2m
step 3550/10000 (35.5%) | 0.55 steps/sec | ETA: 196.6m
step 3575/10000 (35.8%) | 0.55 steps/sec | ETA: 195.0m
step 3600/10000 (36.0%) | 0.55 steps/sec | ETA: 193.4m
step 3625/10000 (36.2%) | 0.55 steps/sec | ETA: 191.9m
step 3650/10000 (36.5%) | 0.56 steps/sec | ETA: 190.4m
step 3675/10000 (36.8%) | 0.56 steps/sec | ETA: 188.9m
step 3700/10000 (37.0%) | 0.56 steps/sec | ETA: 187.4m
step 3725/10000 (37.2%) | 0.56 steps/sec | ETA: 186.0m
step 3750/10000 (37.5%) | 0.56 steps/sec | ETA: 184.7m
step 3775/10000 (37.8%) | 0.57 steps/sec | ETA: 183.3m
step 3800/10000 (38.0%) | 0.57 steps/sec | ETA: 181.9m
step 3825/10000 (38.2%) | 0.57 steps/sec | ETA: 180.6m
step 3850/10000 (38.5%) | 0.57 steps/sec | ETA: 179.2m
step 3875/10000 (38.8%) | 0.57 steps/sec | ETA: 177.9m
step 3900/10000 (39.0%) | 0.58 steps/sec | ETA: 176.6m
step 3925/10000 (39.2%) | 0.58 steps/sec | ETA: 175.3m
step 3950/10000 (39.5%) | 0.58 steps/sec | ETA: 174.0m
step 3975/10000 (39.8%) | 0.58 steps/sec | ETA: 172.8m
step 4000/10000 (40.0%): train loss 7.0090, val loss 7.4579 | LR: 7.75e-06 | 6887.2s (0.58 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step004000_11142025_112302.pt
step 4025/10000 (40.2%) | 0.58 steps/sec | ETA: 171.2m
step 4050/10000 (40.5%) | 0.58 steps/sec | ETA: 169.9m
step 4075/10000 (40.8%) | 0.58 steps/sec | ETA: 168.8m
step 4100/10000 (41.0%) | 0.59 steps/sec | ETA: 167.6m
step 4125/10000 (41.2%) | 0.59 steps/sec | ETA: 166.4m
step 4150/10000 (41.5%) | 0.59 steps/sec | ETA: 165.3m
step 4175/10000 (41.8%) | 0.59 steps/sec | ETA: 164.1m
step 4200/10000 (42.0%) | 0.59 steps/sec | ETA: 163.0m
step 4225/10000 (42.2%) | 0.59 steps/sec | ETA: 161.9m
step 4250/10000 (42.5%) | 0.60 steps/sec | ETA: 160.8m
step 4275/10000 (42.8%) | 0.60 steps/sec | ETA: 159.7m
step 4300/10000 (43.0%) | 0.60 steps/sec | ETA: 158.6m
step 4325/10000 (43.2%) | 0.60 steps/sec | ETA: 157.5m
step 4350/10000 (43.5%) | 0.60 steps/sec | ETA: 156.4m
step 4375/10000 (43.8%) | 0.60 steps/sec | ETA: 155.3m
step 4400/10000 (44.0%) | 0.61 steps/sec | ETA: 154.2m
step 4425/10000 (44.2%) | 0.61 steps/sec | ETA: 153.1m
step 4450/10000 (44.5%) | 0.61 steps/sec | ETA: 152.1m
step 4475/10000 (44.8%) | 0.61 steps/sec | ETA: 151.1m
step 4500/10000 (45.0%): train loss 6.8526, val loss 7.3224 | LR: 7.04e-06 | 7392.3s (0.61 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step004500_11142025_113127.pt
step 4525/10000 (45.2%) | 0.61 steps/sec | ETA: 149.6m
step 4550/10000 (45.5%) | 0.61 steps/sec | ETA: 148.5m
step 4575/10000 (45.8%) | 0.61 steps/sec | ETA: 147.5m
step 4600/10000 (46.0%) | 0.61 steps/sec | ETA: 146.5m
step 4625/10000 (46.2%) | 0.62 steps/sec | ETA: 145.5m
step 4650/10000 (46.5%) | 0.62 steps/sec | ETA: 144.5m
step 4675/10000 (46.8%) | 0.62 steps/sec | ETA: 143.5m
step 4700/10000 (47.0%) | 0.62 steps/sec | ETA: 142.5m
step 4725/10000 (47.2%) | 0.62 steps/sec | ETA: 141.6m
step 4750/10000 (47.5%) | 0.62 steps/sec | ETA: 140.6m
step 4775/10000 (47.8%) | 0.55 steps/sec | ETA: 157.6m
step 4800/10000 (48.0%) | 0.55 steps/sec | ETA: 156.7m
step 4825/10000 (48.2%) | 0.55 steps/sec | ETA: 155.8m
step 4850/10000 (48.5%) | 0.55 steps/sec | ETA: 154.9m
step 4875/10000 (48.8%) | 0.55 steps/sec | ETA: 153.9m
step 4900/10000 (49.0%) | 0.56 steps/sec | ETA: 153.0m
step 4925/10000 (49.2%) | 0.56 steps/sec | ETA: 152.1m
step 4950/10000 (49.5%) | 0.56 steps/sec | ETA: 151.2m
step 4975/10000 (49.8%) | 0.56 steps/sec | ETA: 150.3m
step 5000/10000 (50.0%): train loss 6.9321, val loss 7.3887 | LR: 6.28e-06 | 9006.2s (0.56 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step005000_11142025_115821.pt
step 5025/10000 (50.2%) | 0.56 steps/sec | ETA: 149.3m
step 5050/10000 (50.5%) | 0.56 steps/sec | ETA: 148.5m
step 5075/10000 (50.7%) | 0.56 steps/sec | ETA: 147.6m
step 5100/10000 (51.0%) | 0.56 steps/sec | ETA: 146.7m
step 5125/10000 (51.2%) | 0.56 steps/sec | ETA: 145.9m
step 5150/10000 (51.5%) | 0.56 steps/sec | ETA: 145.0m
step 5175/10000 (51.7%) | 0.56 steps/sec | ETA: 144.1m
step 5200/10000 (52.0%) | 0.56 steps/sec | ETA: 143.3m
step 5225/10000 (52.2%) | 0.56 steps/sec | ETA: 142.4m
step 5250/10000 (52.5%) | 0.56 steps/sec | ETA: 141.6m
step 5275/10000 (52.8%) | 0.56 steps/sec | ETA: 140.7m
step 5300/10000 (53.0%) | 0.56 steps/sec | ETA: 139.9m
step 5325/10000 (53.2%) | 0.56 steps/sec | ETA: 139.0m
step 5350/10000 (53.5%) | 0.56 steps/sec | ETA: 138.2m
step 5375/10000 (53.8%) | 0.56 steps/sec | ETA: 137.3m
step 5400/10000 (54.0%) | 0.56 steps/sec | ETA: 136.5m
step 5425/10000 (54.2%) | 0.56 steps/sec | ETA: 135.7m
step 5450/10000 (54.5%) | 0.56 steps/sec | ETA: 134.8m
step 5475/10000 (54.8%) | 0.56 steps/sec | ETA: 134.0m
step 5500/10000 (55.0%): train loss 6.8925, val loss 7.3289 | LR: 5.50e-06 | 9815.3s (0.56 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step005500_11142025_121150.pt
step 5525/10000 (55.2%) | 0.56 steps/sec | ETA: 133.0m
step 5550/10000 (55.5%) | 0.56 steps/sec | ETA: 132.2m
step 5575/10000 (55.8%) | 0.56 steps/sec | ETA: 131.4m
step 5600/10000 (56.0%) | 0.56 steps/sec | ETA: 130.6m
step 5625/10000 (56.2%) | 0.56 steps/sec | ETA: 129.7m
step 5650/10000 (56.5%) | 0.56 steps/sec | ETA: 128.9m
step 5675/10000 (56.8%) | 0.56 steps/sec | ETA: 128.0m
step 5700/10000 (57.0%) | 0.56 steps/sec | ETA: 127.2m
step 5725/10000 (57.2%) | 0.56 steps/sec | ETA: 126.4m
step 5750/10000 (57.5%) | 0.56 steps/sec | ETA: 125.6m
step 5775/10000 (57.8%) | 0.56 steps/sec | ETA: 124.8m
step 5800/10000 (58.0%) | 0.56 steps/sec | ETA: 124.0m
step 5825/10000 (58.2%) | 0.56 steps/sec | ETA: 123.2m
step 5850/10000 (58.5%) | 0.57 steps/sec | ETA: 122.3m
step 5875/10000 (58.8%) | 0.57 steps/sec | ETA: 121.5m
step 5900/10000 (59.0%) | 0.57 steps/sec | ETA: 120.7m
step 5925/10000 (59.2%) | 0.57 steps/sec | ETA: 119.9m
step 5950/10000 (59.5%) | 0.57 steps/sec | ETA: 119.1m
step 5975/10000 (59.8%) | 0.57 steps/sec | ETA: 118.3m
step 6000/10000 (60.0%): train loss 6.8378, val loss 7.4227 | LR: 4.72e-06 | 10605.2s (0.57 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step006000_11142025_122500.pt
step 6025/10000 (60.2%) | 0.57 steps/sec | ETA: 117.0m
step 6050/10000 (60.5%) | 0.57 steps/sec | ETA: 116.2m
step 6075/10000 (60.8%) | 0.57 steps/sec | ETA: 115.4m
step 6100/10000 (61.0%) | 0.57 steps/sec | ETA: 114.6m
step 6125/10000 (61.3%) | 0.57 steps/sec | ETA: 113.8m
step 6150/10000 (61.5%) | 0.57 steps/sec | ETA: 113.0m
step 6175/10000 (61.8%) | 0.57 steps/sec | ETA: 112.2m
step 6200/10000 (62.0%) | 0.57 steps/sec | ETA: 111.4m
step 6225/10000 (62.3%) | 0.57 steps/sec | ETA: 110.5m
step 6250/10000 (62.5%) | 0.57 steps/sec | ETA: 109.7m
step 6275/10000 (62.7%) | 0.57 steps/sec | ETA: 108.9m
step 6300/10000 (63.0%) | 0.57 steps/sec | ETA: 108.1m
step 6325/10000 (63.2%) | 0.57 steps/sec | ETA: 107.3m
step 6350/10000 (63.5%) | 0.57 steps/sec | ETA: 106.5m
step 6375/10000 (63.7%) | 0.57 steps/sec | ETA: 105.7m
step 6400/10000 (64.0%) | 0.57 steps/sec | ETA: 104.9m
step 6425/10000 (64.2%) | 0.57 steps/sec | ETA: 104.1m
step 6450/10000 (64.5%) | 0.57 steps/sec | ETA: 103.3m
step 6475/10000 (64.8%) | 0.57 steps/sec | ETA: 102.6m
step 6500/10000 (65.0%): train loss 7.0641, val loss 7.5730 | LR: 3.96e-06 | 11373.5s (0.57 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step006500_11142025_123749.pt
step 6525/10000 (65.2%) | 0.57 steps/sec | ETA: 101.3m
step 6550/10000 (65.5%) | 0.57 steps/sec | ETA: 100.5m
step 6575/10000 (65.8%) | 0.57 steps/sec | ETA: 99.7m
step 6600/10000 (66.0%) | 0.57 steps/sec | ETA: 98.9m
step 6625/10000 (66.2%) | 0.57 steps/sec | ETA: 98.1m
step 6650/10000 (66.5%) | 0.57 steps/sec | ETA: 97.3m
step 6675/10000 (66.8%) | 0.57 steps/sec | ETA: 96.5m
step 6700/10000 (67.0%) | 0.57 steps/sec | ETA: 95.8m
step 6725/10000 (67.2%) | 0.57 steps/sec | ETA: 95.0m
step 6750/10000 (67.5%) | 0.57 steps/sec | ETA: 94.2m
step 6775/10000 (67.8%) | 0.58 steps/sec | ETA: 93.4m
step 6800/10000 (68.0%) | 0.58 steps/sec | ETA: 92.7m
step 6825/10000 (68.2%) | 0.58 steps/sec | ETA: 91.9m
step 6850/10000 (68.5%) | 0.58 steps/sec | ETA: 91.2m
step 6875/10000 (68.8%) | 0.58 steps/sec | ETA: 90.4m
step 6900/10000 (69.0%) | 0.58 steps/sec | ETA: 89.7m
step 6925/10000 (69.2%) | 0.58 steps/sec | ETA: 88.9m
step 6950/10000 (69.5%) | 0.58 steps/sec | ETA: 88.2m
step 6975/10000 (69.8%) | 0.58 steps/sec | ETA: 87.4m
step 7000/10000 (70.0%): train loss 7.1650, val loss 7.6750 | LR: 3.25e-06 | 12159.1s (0.58 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step007000_11142025_125054.pt
step 7025/10000 (70.2%) | 0.58 steps/sec | ETA: 86.1m
step 7050/10000 (70.5%) | 0.58 steps/sec | ETA: 85.3m
step 7075/10000 (70.8%) | 0.58 steps/sec | ETA: 84.6m
step 7100/10000 (71.0%) | 0.58 steps/sec | ETA: 83.8m
step 7125/10000 (71.2%) | 0.58 steps/sec | ETA: 83.0m
step 7150/10000 (71.5%) | 0.58 steps/sec | ETA: 82.2m
step 7175/10000 (71.8%) | 0.58 steps/sec | ETA: 81.5m
step 7200/10000 (72.0%) | 0.58 steps/sec | ETA: 80.7m
step 7225/10000 (72.2%) | 0.58 steps/sec | ETA: 79.9m
step 7250/10000 (72.5%) | 0.58 steps/sec | ETA: 79.2m
step 7275/10000 (72.8%) | 0.58 steps/sec | ETA: 78.3m
step 7300/10000 (73.0%) | 0.58 steps/sec | ETA: 77.5m
step 7325/10000 (73.2%) | 0.58 steps/sec | ETA: 76.6m
step 7350/10000 (73.5%) | 0.58 steps/sec | ETA: 75.8m
step 7375/10000 (73.8%) | 0.58 steps/sec | ETA: 74.9m
step 7400/10000 (74.0%) | 0.58 steps/sec | ETA: 74.1m
step 7425/10000 (74.2%) | 0.59 steps/sec | ETA: 73.3m
step 7450/10000 (74.5%) | 0.59 steps/sec | ETA: 72.5m
step 7475/10000 (74.8%) | 0.59 steps/sec | ETA: 71.7m
step 7500/10000 (75.0%): train loss 7.0181, val loss 7.6317 | LR: 2.61e-06 | 12803.0s (0.59 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step007500_11142025_130138.pt
step 7525/10000 (75.2%) | 0.59 steps/sec | ETA: 70.4m
step 7550/10000 (75.5%) | 0.59 steps/sec | ETA: 69.6m
step 7575/10000 (75.8%) | 0.59 steps/sec | ETA: 68.9m
step 7600/10000 (76.0%) | 0.59 steps/sec | ETA: 68.1m
step 7625/10000 (76.2%) | 0.59 steps/sec | ETA: 67.3m
step 7650/10000 (76.5%) | 0.59 steps/sec | ETA: 66.6m
step 7675/10000 (76.8%) | 0.59 steps/sec | ETA: 65.9m
step 7700/10000 (77.0%) | 0.59 steps/sec | ETA: 65.2m
step 7725/10000 (77.2%) | 0.59 steps/sec | ETA: 64.5m
step 7750/10000 (77.5%) | 0.59 steps/sec | ETA: 63.7m
step 7775/10000 (77.8%) | 0.59 steps/sec | ETA: 63.0m
step 7800/10000 (78.0%) | 0.59 steps/sec | ETA: 62.2m
step 7825/10000 (78.2%) | 0.59 steps/sec | ETA: 61.4m
step 7850/10000 (78.5%) | 0.59 steps/sec | ETA: 60.7m
step 7875/10000 (78.8%) | 0.59 steps/sec | ETA: 59.9m
step 7900/10000 (79.0%) | 0.59 steps/sec | ETA: 59.1m
step 7925/10000 (79.2%) | 0.59 steps/sec | ETA: 58.4m
step 7950/10000 (79.5%) | 0.59 steps/sec | ETA: 57.6m
step 7975/10000 (79.8%) | 0.59 steps/sec | ETA: 56.9m
step 8000/10000 (80.0%): train loss 6.9144, val loss 7.5450 | LR: 2.05e-06 | 13499.2s (0.59 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step008000_11142025_131314.pt
step 8025/10000 (80.2%) | 0.59 steps/sec | ETA: 55.5m
step 8050/10000 (80.5%) | 0.59 steps/sec | ETA: 54.8m
step 8075/10000 (80.8%) | 0.59 steps/sec | ETA: 54.0m
step 8100/10000 (81.0%) | 0.59 steps/sec | ETA: 53.3m
step 8125/10000 (81.2%) | 0.60 steps/sec | ETA: 52.5m
step 8150/10000 (81.5%) | 0.60 steps/sec | ETA: 51.8m
step 8175/10000 (81.8%) | 0.60 steps/sec | ETA: 51.0m
step 8200/10000 (82.0%) | 0.60 steps/sec | ETA: 50.3m
step 8225/10000 (82.2%) | 0.60 steps/sec | ETA: 49.5m
step 8250/10000 (82.5%) | 0.60 steps/sec | ETA: 48.8m
step 8275/10000 (82.8%) | 0.60 steps/sec | ETA: 48.0m
step 8300/10000 (83.0%) | 0.60 steps/sec | ETA: 47.3m
step 8325/10000 (83.2%) | 0.60 steps/sec | ETA: 46.6m
step 8350/10000 (83.5%) | 0.60 steps/sec | ETA: 45.8m
step 8375/10000 (83.8%) | 0.60 steps/sec | ETA: 45.1m
step 8400/10000 (84.0%) | 0.60 steps/sec | ETA: 44.4m
step 8425/10000 (84.2%) | 0.60 steps/sec | ETA: 43.7m
step 8450/10000 (84.5%) | 0.60 steps/sec | ETA: 43.0m
step 8475/10000 (84.8%) | 0.60 steps/sec | ETA: 42.3m
step 8500/10000 (85.0%): train loss 6.9022, val loss 7.5337 | LR: 1.60e-06 | 14158.9s (0.60 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step008500_11142025_132414.pt
step 8525/10000 (85.2%) | 0.60 steps/sec | ETA: 40.9m
step 8550/10000 (85.5%) | 0.60 steps/sec | ETA: 40.2m
step 8575/10000 (85.8%) | 0.60 steps/sec | ETA: 39.5m
step 8600/10000 (86.0%) | 0.60 steps/sec | ETA: 38.7m
step 8625/10000 (86.2%) | 0.60 steps/sec | ETA: 38.0m
step 8650/10000 (86.5%) | 0.60 steps/sec | ETA: 37.3m
step 8675/10000 (86.8%) | 0.60 steps/sec | ETA: 36.6m
step 8700/10000 (87.0%) | 0.60 steps/sec | ETA: 35.8m
step 8725/10000 (87.2%) | 0.61 steps/sec | ETA: 35.1m
step 8750/10000 (87.5%) | 0.61 steps/sec | ETA: 34.4m
step 8775/10000 (87.8%) | 0.61 steps/sec | ETA: 33.7m
step 8800/10000 (88.0%) | 0.61 steps/sec | ETA: 33.0m
step 8825/10000 (88.2%) | 0.61 steps/sec | ETA: 32.3m
step 8850/10000 (88.5%) | 0.61 steps/sec | ETA: 31.5m
step 8875/10000 (88.8%) | 0.61 steps/sec | ETA: 30.8m
step 8900/10000 (89.0%) | 0.61 steps/sec | ETA: 30.1m
step 8925/10000 (89.2%) | 0.61 steps/sec | ETA: 29.4m
step 8950/10000 (89.5%) | 0.61 steps/sec | ETA: 28.7m
step 8975/10000 (89.8%) | 0.61 steps/sec | ETA: 28.0m
step 9000/10000 (90.0%): train loss 6.9506, val loss 7.5116 | LR: 1.27e-06 | 14771.1s (0.61 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step009000_11142025_133426.pt
step 9025/10000 (90.2%) | 0.61 steps/sec | ETA: 26.7m
step 9050/10000 (90.5%) | 0.61 steps/sec | ETA: 26.0m
step 9075/10000 (90.8%) | 0.61 steps/sec | ETA: 25.3m
step 9100/10000 (91.0%) | 0.61 steps/sec | ETA: 24.6m
step 9125/10000 (91.2%) | 0.61 steps/sec | ETA: 23.9m
step 9150/10000 (91.5%) | 0.61 steps/sec | ETA: 23.2m
step 9175/10000 (91.8%) | 0.61 steps/sec | ETA: 22.5m
step 9200/10000 (92.0%) | 0.58 steps/sec | ETA: 23.0m
step 9225/10000 (92.2%) | 0.58 steps/sec | ETA: 22.2m
step 9250/10000 (92.5%) | 0.58 steps/sec | ETA: 21.5m
step 9275/10000 (92.8%) | 0.58 steps/sec | ETA: 20.7m
step 9300/10000 (93.0%) | 0.58 steps/sec | ETA: 20.0m
step 9325/10000 (93.2%) | 0.58 steps/sec | ETA: 19.2m
step 9350/10000 (93.5%) | 0.59 steps/sec | ETA: 18.5m
step 9375/10000 (93.8%) | 0.59 steps/sec | ETA: 17.8m
step 9400/10000 (94.0%) | 0.59 steps/sec | ETA: 17.0m
step 9425/10000 (94.2%) | 0.59 steps/sec | ETA: 16.3m
step 9450/10000 (94.5%) | 0.59 steps/sec | ETA: 15.6m
step 9475/10000 (94.8%) | 0.59 steps/sec | ETA: 14.8m
step 9500/10000 (95.0%): train loss 6.9715, val loss 7.5254 | LR: 1.07e-06 | 16127.1s (0.59 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step009500_11142025_135702.pt
step 9525/10000 (95.2%) | 0.59 steps/sec | ETA: 13.4m
step 9550/10000 (95.5%) | 0.59 steps/sec | ETA: 12.7m
step 9575/10000 (95.8%) | 0.59 steps/sec | ETA: 12.0m
step 9600/10000 (96.0%) | 0.59 steps/sec | ETA: 11.3m
step 9625/10000 (96.2%) | 0.59 steps/sec | ETA: 10.6m
step 9650/10000 (96.5%) | 0.59 steps/sec | ETA: 9.9m
step 9675/10000 (96.8%) | 0.59 steps/sec | ETA: 9.1m
step 9700/10000 (97.0%) | 0.59 steps/sec | ETA: 8.4m
step 9725/10000 (97.2%) | 0.59 steps/sec | ETA: 7.7m
step 9750/10000 (97.5%) | 0.59 steps/sec | ETA: 7.0m
step 9775/10000 (97.8%) | 0.59 steps/sec | ETA: 6.3m
step 9800/10000 (98.0%) | 0.60 steps/sec | ETA: 5.6m
step 9825/10000 (98.2%) | 0.60 steps/sec | ETA: 4.9m
step 9850/10000 (98.5%) | 0.60 steps/sec | ETA: 4.2m
step 9875/10000 (98.8%) | 0.60 steps/sec | ETA: 3.5m
step 9900/10000 (99.0%) | 0.60 steps/sec | ETA: 2.8m
step 9925/10000 (99.2%) | 0.60 steps/sec | ETA: 2.1m
step 9950/10000 (99.5%) | 0.60 steps/sec | ETA: 1.4m
step 9975/10000 (99.8%) | 0.60 steps/sec | ETA: 0.7m
--------------------------------------------------
Training complete! Final loss: 7.4652
Total training time: 4h 37m 54s (0.60 steps/sec)
‚úÖ Final model saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_cleaned_step010000_11142025_140610.pt

Generating text...
==================================================

:. all the I't a about of to time
olynt. it'tÔøΩice's of
ION theÔøΩax. the andÔøΩWER H
: It. all-'s the the't
ION I isÔøΩice and, he't's-ÔøΩice him't.
ax, a.,.
:
:
 H I
:
sÔøΩolyn H you
ax/ you and. have, a.?. I't't.
s it
:, have of/ she't youÔøΩION
WER., to't of,'t, ago
ax the't his. to't the, herÔøΩice from. and to to't,. I to to allÔøΩ:'s toÔøΩice,
s a you for
 H the a't...ist't't.,ÔøΩs't and.
t,, a't and toÔøΩIf the't, to was toistÔøΩI ofÔøΩION? to,.
ION is't.ÔøΩ
s't,ist about to't a,ÔøΩice,'t. a aÔøΩice
s a a
WER we
ION do it he're and't,.ÔøΩ about of.
: is this't, aist't't the I was't, from, it to outÔøΩt,, a. for a't have a't't'sÔøΩax at a his't't
ION
ax to-ÔøΩ isist
==================================================
