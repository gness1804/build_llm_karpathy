HYPERPARAMETERS
================
batch_size = 16
block_size = 64
training_steps = 5000
eval_interval = 500
learning_rate = 0.0003
eval_iters = 20
n_embd = 256
n_head = 4
n_layer = 4
dropout = 0.2
max_new_tokens = 300
device = mps
tokenization_method = character
test_mode = False
use_lora = True
model_type = gpt2
training_data_source = sources/carolyn_hax_merged.md
gpt2_model_name = gpt2
lora_rank = 8
lora_alpha = 16.0
lora_dropout = 0.0

OUTPUT
======
üöÄ FULL MODE: Using production hyperparameters (aggressively optimized for M4)
   üìå GPT-2 detected: Using optimized batch/block sizes for MPS
‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)
Device: mps
Model size: 4 layers, 256 embedding dims, 4 heads
ü§ñ Using GPT-2 model: gpt2
üîß Using LoRA for efficient fine-tuning
   LoRA rank: 8, alpha: 16.0, dropout: 0.0
üì• Loading gpt2 from HuggingFace...
   Applied LoRA to 49 layers
‚úÖ LoRA adapters applied (rank=8, alpha=16.0)
üìä Parameter Statistics:
   Model: gpt2
   Total parameters: 126,027,656
   Trainable (total): 1,587,848
   Frozen (base model): 124,439,808
   üí∞ LoRA savings: Training only 1.26% of parameters!
Model device: mps:0
‚úÖ Model successfully moved to Apple Silicon GPU (MPS)
‚ÑπÔ∏è  Using MPS without compilation (torch.compile disabled for MPS)
‚úÖ Optimizer initialized with 98 parameter groups (LoRA only)
Starting training for 5000 steps...
Batch size: 16, Block size: 64
Vocabulary size: 50,257 tokens
Checkpoints enabled: saving every 500 steps to checkpoints/
--------------------------------------------------
step 0/5000 (0.0%): train loss 9.6122, val loss 9.6393 | 8.2s (0.00 steps/sec)
step 25/5000 (0.5%) | 1.46 steps/sec | ETA: 56.6m
step 50/5000 (1.0%) | 1.94 steps/sec | ETA: 42.4m
step 75/5000 (1.5%) | 2.18 steps/sec | ETA: 37.6m
step 100/5000 (2.0%) | 2.26 steps/sec | ETA: 36.2m
step 125/5000 (2.5%) | 2.35 steps/sec | ETA: 34.6m
step 150/5000 (3.0%) | 2.42 steps/sec | ETA: 33.3m
step 175/5000 (3.5%) | 2.48 steps/sec | ETA: 32.4m
step 200/5000 (4.0%) | 2.52 steps/sec | ETA: 31.7m
step 225/5000 (4.5%) | 2.56 steps/sec | ETA: 31.1m
step 250/5000 (5.0%) | 2.59 steps/sec | ETA: 30.6m
step 275/5000 (5.5%) | 2.61 steps/sec | ETA: 30.1m
step 300/5000 (6.0%) | 2.63 steps/sec | ETA: 29.7m
step 325/5000 (6.5%) | 2.65 steps/sec | ETA: 29.4m
step 350/5000 (7.0%) | 2.67 steps/sec | ETA: 29.1m
step 375/5000 (7.5%) | 2.68 steps/sec | ETA: 28.8m
step 400/5000 (8.0%) | 2.69 steps/sec | ETA: 28.5m
step 425/5000 (8.5%) | 2.70 steps/sec | ETA: 28.2m
step 450/5000 (9.0%) | 2.71 steps/sec | ETA: 28.0m
step 475/5000 (9.5%) | 2.72 steps/sec | ETA: 27.7m
step 500/5000 (10.0%): train loss 6.5482, val loss 6.9646 | 191.9s (2.61 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step000500_11132025_182701.pt
step 525/5000 (10.5%) | 2.60 steps/sec | ETA: 28.7m
step 550/5000 (11.0%) | 2.60 steps/sec | ETA: 28.5m
step 575/5000 (11.5%) | 2.61 steps/sec | ETA: 28.3m
step 600/5000 (12.0%) | 2.61 steps/sec | ETA: 28.1m
step 625/5000 (12.5%) | 2.60 steps/sec | ETA: 28.0m
step 650/5000 (13.0%) | 2.60 steps/sec | ETA: 27.9m
step 675/5000 (13.5%) | 2.59 steps/sec | ETA: 27.8m
step 700/5000 (14.0%) | 2.59 steps/sec | ETA: 27.7m
step 725/5000 (14.5%) | 2.59 steps/sec | ETA: 27.6m
step 750/5000 (15.0%) | 2.58 steps/sec | ETA: 27.4m
step 775/5000 (15.5%) | 2.58 steps/sec | ETA: 27.3m
step 800/5000 (16.0%) | 2.57 steps/sec | ETA: 27.2m
step 825/5000 (16.5%) | 2.57 steps/sec | ETA: 27.1m
step 850/5000 (17.0%) | 2.57 steps/sec | ETA: 26.9m
step 875/5000 (17.5%) | 2.55 steps/sec | ETA: 26.9m
step 900/5000 (18.0%) | 2.55 steps/sec | ETA: 26.8m
step 925/5000 (18.5%) | 2.54 steps/sec | ETA: 26.7m
step 950/5000 (19.0%) | 2.54 steps/sec | ETA: 26.6m
step 975/5000 (19.5%) | 2.54 steps/sec | ETA: 26.4m
step 1000/5000 (20.0%): train loss 6.0088, val loss 6.4066 | 404.5s (2.47 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step001000_11132025_183034.pt
step 1025/5000 (20.5%) | 2.46 steps/sec | ETA: 26.9m
step 1050/5000 (21.0%) | 2.46 steps/sec | ETA: 26.7m
step 1075/5000 (21.5%) | 2.46 steps/sec | ETA: 26.6m
step 1100/5000 (22.0%) | 2.46 steps/sec | ETA: 26.4m
step 1125/5000 (22.5%) | 2.46 steps/sec | ETA: 26.2m
step 1150/5000 (23.0%) | 2.46 steps/sec | ETA: 26.1m
step 1175/5000 (23.5%) | 2.46 steps/sec | ETA: 25.9m
step 1200/5000 (24.0%) | 2.46 steps/sec | ETA: 25.8m
step 1225/5000 (24.5%) | 2.46 steps/sec | ETA: 25.6m
step 1250/5000 (25.0%) | 2.46 steps/sec | ETA: 25.4m
step 1275/5000 (25.5%) | 2.46 steps/sec | ETA: 25.3m
step 1300/5000 (26.0%) | 2.46 steps/sec | ETA: 25.1m
step 1325/5000 (26.5%) | 2.45 steps/sec | ETA: 25.0m
step 1350/5000 (27.0%) | 2.45 steps/sec | ETA: 24.8m
step 1375/5000 (27.5%) | 2.45 steps/sec | ETA: 24.6m
step 1400/5000 (28.0%) | 2.45 steps/sec | ETA: 24.5m
step 1425/5000 (28.5%) | 2.44 steps/sec | ETA: 24.4m
step 1450/5000 (29.0%) | 2.44 steps/sec | ETA: 24.2m
step 1475/5000 (29.5%) | 2.44 steps/sec | ETA: 24.1m
step 1500/5000 (30.0%): train loss 6.2093, val loss 6.8341 | 625.6s (2.40 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step001500_11132025_183415.pt
step 1525/5000 (30.5%) | 2.39 steps/sec | ETA: 24.2m
step 1550/5000 (31.0%) | 2.39 steps/sec | ETA: 24.1m
step 1575/5000 (31.5%) | 2.39 steps/sec | ETA: 23.9m
step 1600/5000 (32.0%) | 2.39 steps/sec | ETA: 23.7m
step 1625/5000 (32.5%) | 2.39 steps/sec | ETA: 23.5m
step 1650/5000 (33.0%) | 2.39 steps/sec | ETA: 23.4m
step 1675/5000 (33.5%) | 1.02 steps/sec | ETA: 54.1m
step 1700/5000 (34.0%) | 1.03 steps/sec | ETA: 53.5m
step 1725/5000 (34.5%) | 1.03 steps/sec | ETA: 52.8m
step 1750/5000 (35.0%) | 1.04 steps/sec | ETA: 52.3m
step 1775/5000 (35.5%) | 1.04 steps/sec | ETA: 51.6m
step 1800/5000 (36.0%) | 1.05 steps/sec | ETA: 51.0m
step 1825/5000 (36.5%) | 1.05 steps/sec | ETA: 50.4m
step 1850/5000 (37.0%) | 1.05 steps/sec | ETA: 49.8m
step 1875/5000 (37.5%) | 1.06 steps/sec | ETA: 49.3m
step 1900/5000 (38.0%) | 1.06 steps/sec | ETA: 48.7m
step 1925/5000 (38.5%) | 1.07 steps/sec | ETA: 48.1m
step 1950/5000 (39.0%) | 1.07 steps/sec | ETA: 47.5m
step 1975/5000 (39.5%) | 1.07 steps/sec | ETA: 47.0m
step 2000/5000 (40.0%): train loss 6.4458, val loss 7.2274 | 1874.3s (1.07 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step002000_11132025_185503.pt
step 2025/5000 (40.5%) | 1.07 steps/sec | ETA: 46.3m
step 2050/5000 (41.0%) | 1.07 steps/sec | ETA: 45.8m
step 2075/5000 (41.5%) | 1.08 steps/sec | ETA: 45.3m
step 2100/5000 (42.0%) | 1.08 steps/sec | ETA: 44.7m
step 2125/5000 (42.5%) | 1.08 steps/sec | ETA: 44.2m
step 2150/5000 (43.0%) | 1.09 steps/sec | ETA: 43.7m
step 2175/5000 (43.5%) | 1.09 steps/sec | ETA: 43.2m
step 2200/5000 (44.0%) | 1.09 steps/sec | ETA: 42.7m
step 2225/5000 (44.5%) | 1.10 steps/sec | ETA: 42.2m
step 2250/5000 (45.0%) | 1.10 steps/sec | ETA: 41.7m
step 2275/5000 (45.5%) | 1.10 steps/sec | ETA: 41.2m
step 2300/5000 (46.0%) | 1.11 steps/sec | ETA: 40.7m
step 2325/5000 (46.5%) | 1.11 steps/sec | ETA: 40.2m
step 2350/5000 (47.0%) | 1.11 steps/sec | ETA: 39.7m
step 2375/5000 (47.5%) | 1.11 steps/sec | ETA: 39.3m
step 2400/5000 (48.0%) | 1.12 steps/sec | ETA: 38.8m
step 2425/5000 (48.5%) | 1.12 steps/sec | ETA: 38.3m
step 2450/5000 (49.0%) | 1.12 steps/sec | ETA: 37.8m
step 2475/5000 (49.5%) | 1.13 steps/sec | ETA: 37.4m
step 2500/5000 (50.0%): train loss 5.8560, val loss 6.7589 | 2231.2s (1.12 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step002500_11132025_190100.pt
step 2525/5000 (50.5%) | 1.12 steps/sec | ETA: 36.8m
step 2550/5000 (51.0%) | 1.12 steps/sec | ETA: 36.3m
step 2575/5000 (51.5%) | 1.13 steps/sec | ETA: 35.9m
step 2600/5000 (52.0%) | 1.13 steps/sec | ETA: 35.4m
step 2625/5000 (52.5%) | 1.13 steps/sec | ETA: 35.0m
step 2650/5000 (53.0%) | 1.14 steps/sec | ETA: 34.5m
step 2675/5000 (53.5%) | 1.14 steps/sec | ETA: 34.1m
step 2700/5000 (54.0%) | 1.14 steps/sec | ETA: 33.6m
step 2725/5000 (54.5%) | 1.14 steps/sec | ETA: 33.2m
step 2750/5000 (55.0%) | 1.14 steps/sec | ETA: 32.8m
step 2775/5000 (55.5%) | 1.14 steps/sec | ETA: 32.4m
step 2800/5000 (56.0%) | 1.14 steps/sec | ETA: 32.1m
step 2825/5000 (56.5%) | 1.14 steps/sec | ETA: 31.8m
step 2850/5000 (57.0%) | 1.14 steps/sec | ETA: 31.4m
step 2875/5000 (57.5%) | 1.15 steps/sec | ETA: 30.9m
step 2900/5000 (58.0%) | 1.15 steps/sec | ETA: 30.5m
step 2925/5000 (58.5%) | 1.15 steps/sec | ETA: 30.1m
step 2950/5000 (59.0%) | 1.15 steps/sec | ETA: 29.7m
step 2975/5000 (59.5%) | 1.15 steps/sec | ETA: 29.3m
step 3000/5000 (60.0%): train loss 5.6459, val loss 6.5116 | 2612.6s (1.15 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step003000_11132025_190722.pt
step 3025/5000 (60.5%) | 1.15 steps/sec | ETA: 28.6m
step 3050/5000 (61.0%) | 1.15 steps/sec | ETA: 28.2m
step 3075/5000 (61.5%) | 1.15 steps/sec | ETA: 27.8m
step 3100/5000 (62.0%) | 1.16 steps/sec | ETA: 27.4m
step 3125/5000 (62.5%) | 1.16 steps/sec | ETA: 27.0m
step 3150/5000 (63.0%) | 1.16 steps/sec | ETA: 26.6m
step 3175/5000 (63.5%) | 1.16 steps/sec | ETA: 26.2m
step 3200/5000 (64.0%) | 1.16 steps/sec | ETA: 25.8m
step 3225/5000 (64.5%) | 1.17 steps/sec | ETA: 25.4m
step 3250/5000 (65.0%) | 1.17 steps/sec | ETA: 25.0m
step 3275/5000 (65.5%) | 1.17 steps/sec | ETA: 24.6m
step 3300/5000 (66.0%) | 1.17 steps/sec | ETA: 24.2m
step 3325/5000 (66.5%) | 1.17 steps/sec | ETA: 23.8m
step 3350/5000 (67.0%) | 1.17 steps/sec | ETA: 23.4m
step 3375/5000 (67.5%) | 1.18 steps/sec | ETA: 23.0m
step 3400/5000 (68.0%) | 1.18 steps/sec | ETA: 22.6m
step 3425/5000 (68.5%) | 1.18 steps/sec | ETA: 22.3m
step 3450/5000 (69.0%) | 1.18 steps/sec | ETA: 21.9m
step 3475/5000 (69.5%) | 1.18 steps/sec | ETA: 21.5m
step 3500/5000 (70.0%): train loss 5.6210, val loss 6.5122 | 2974.6s (1.18 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step003500_11132025_191324.pt
step 3525/5000 (70.5%) | 1.18 steps/sec | ETA: 20.9m
step 3550/5000 (71.0%) | 1.18 steps/sec | ETA: 20.5m
step 3575/5000 (71.5%) | 1.18 steps/sec | ETA: 20.1m
step 3600/5000 (72.0%) | 1.18 steps/sec | ETA: 19.7m
step 3625/5000 (72.5%) | 1.18 steps/sec | ETA: 19.4m
step 3650/5000 (73.0%) | 1.19 steps/sec | ETA: 19.0m
step 3675/5000 (73.5%) | 1.19 steps/sec | ETA: 18.6m
step 3700/5000 (74.0%) | 1.19 steps/sec | ETA: 18.2m
step 3725/5000 (74.5%) | 1.19 steps/sec | ETA: 17.9m
step 3750/5000 (75.0%) | 1.19 steps/sec | ETA: 17.5m
step 3775/5000 (75.5%) | 1.19 steps/sec | ETA: 17.1m
step 3800/5000 (76.0%) | 1.19 steps/sec | ETA: 16.7m
step 3825/5000 (76.5%) | 1.20 steps/sec | ETA: 16.4m
step 3850/5000 (77.0%) | 1.20 steps/sec | ETA: 16.0m
step 3875/5000 (77.5%) | 1.20 steps/sec | ETA: 15.6m
step 3900/5000 (78.0%) | 1.20 steps/sec | ETA: 15.3m
step 3925/5000 (78.5%) | 1.20 steps/sec | ETA: 14.9m
step 3950/5000 (79.0%) | 1.20 steps/sec | ETA: 14.6m
step 3975/5000 (79.5%) | 1.20 steps/sec | ETA: 14.2m
step 4000/5000 (80.0%): train loss 5.7598, val loss 6.4528 | 3337.3s (1.20 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step004000_11132025_191926.pt
step 4025/5000 (80.5%) | 1.20 steps/sec | ETA: 13.5m
step 4050/5000 (81.0%) | 1.20 steps/sec | ETA: 13.2m
step 4075/5000 (81.5%) | 1.20 steps/sec | ETA: 12.8m
step 4100/5000 (82.0%) | 1.20 steps/sec | ETA: 12.5m
step 4125/5000 (82.5%) | 1.20 steps/sec | ETA: 12.1m
step 4150/5000 (83.0%) | 1.21 steps/sec | ETA: 11.7m
step 4175/5000 (83.5%) | 1.21 steps/sec | ETA: 11.4m
step 4200/5000 (84.0%) | 1.21 steps/sec | ETA: 11.0m
step 4225/5000 (84.5%) | 1.21 steps/sec | ETA: 10.7m
step 4250/5000 (85.0%) | 1.21 steps/sec | ETA: 10.3m
step 4275/5000 (85.5%) | 1.21 steps/sec | ETA: 10.0m
step 4300/5000 (86.0%) | 1.21 steps/sec | ETA: 9.6m
step 4325/5000 (86.5%) | 1.21 steps/sec | ETA: 9.3m
step 4350/5000 (87.0%) | 1.22 steps/sec | ETA: 8.9m
step 4375/5000 (87.5%) | 1.22 steps/sec | ETA: 8.6m
step 4400/5000 (88.0%) | 1.22 steps/sec | ETA: 8.2m
step 4425/5000 (88.5%) | 1.22 steps/sec | ETA: 7.9m
step 4450/5000 (89.0%) | 1.22 steps/sec | ETA: 7.5m
step 4475/5000 (89.5%) | 1.22 steps/sec | ETA: 7.2m
step 4500/5000 (90.0%): train loss 5.8120, val loss 6.7338 | 3697.6s (1.22 steps/sec)
   üíæ Checkpoint saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step004500_11132025_192527.pt
step 4525/5000 (90.5%) | 1.22 steps/sec | ETA: 6.5m
step 4550/5000 (91.0%) | 1.22 steps/sec | ETA: 6.2m
step 4575/5000 (91.5%) | 1.22 steps/sec | ETA: 5.8m
step 4600/5000 (92.0%) | 1.22 steps/sec | ETA: 5.5m
step 4625/5000 (92.5%) | 1.22 steps/sec | ETA: 5.1m
step 4650/5000 (93.0%) | 1.22 steps/sec | ETA: 4.8m
step 4675/5000 (93.5%) | 1.22 steps/sec | ETA: 4.4m
step 4700/5000 (94.0%) | 1.23 steps/sec | ETA: 4.1m
step 4725/5000 (94.5%) | 1.23 steps/sec | ETA: 3.7m
step 4750/5000 (95.0%) | 1.23 steps/sec | ETA: 3.4m
step 4775/5000 (95.5%) | 1.23 steps/sec | ETA: 3.1m
step 4800/5000 (96.0%) | 1.23 steps/sec | ETA: 2.7m
step 4825/5000 (96.5%) | 1.23 steps/sec | ETA: 2.4m
step 4850/5000 (97.0%) | 1.23 steps/sec | ETA: 2.0m
step 4875/5000 (97.5%) | 1.23 steps/sec | ETA: 1.7m
step 4900/5000 (98.0%) | 1.23 steps/sec | ETA: 1.4m
step 4925/5000 (98.5%) | 1.24 steps/sec | ETA: 1.0m
step 4950/5000 (99.0%) | 1.24 steps/sec | ETA: 0.7m
step 4975/5000 (99.5%) | 1.24 steps/sec | ETA: 0.3m
--------------------------------------------------
Training complete! Final loss: 6.2139
Total training time: 1h 7m 17s (1.24 steps/sec)
‚úÖ Final model saved: checkpoints/checkpoint_gpt2_carolyn_hax_merged_step005000_11132025_193107.pt

Generating text...
==================================================
 butPost 0 and
,: and
 I'tÔøΩ not was who.
ÔøΩt--laws
 Sep, thinkÔøΩt and a for and I to.av
 has afternoon the to things I sorry this, of of for with to my, just to to. this to the. Enter expandFor toÔøΩt?Guest 16 1208...QUEST: it't who.
I about the Carolyn the and is, would to and it doÔøΩm
WER Enter expand11Guest 1605sav
Press to
ION_ of.
ION
ION_ this.Guest 26Guest 635: pm
IONPress to
WERPress to
ION Sens is and24
IONPress toQUEST: the of with life with and. Enter expandFor.
 May, my- for. Enter expandHGuest 13: pm
ION I not of with toQUEST: toQUEST: youÔøΩs the of of and.
================m
 has of). my is happy on kids the is.. the a of dog are the,'s of. a or to05 I how wife notÔøΩm
ice.QUEST:ÔøΩm
ice.QUEST: is a is.
 has goodÔøΩ my mom the to.Guest 326
ION My person the in andING.
ÔøΩs's as.
Press to
ION
ION
 has.av
Press toQUEST:
ice. you like, mom who like
==================================================
