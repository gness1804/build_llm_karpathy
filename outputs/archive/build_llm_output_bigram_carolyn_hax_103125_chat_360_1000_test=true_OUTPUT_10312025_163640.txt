HYPERPARAMETERS
================
batch_size = 32
block_size = 64
training_steps = 1000
eval_interval = 100
learning_rate = 0.0003
eval_iters = 50
n_embd = 128
n_head = 4
n_layer = 3
dropout = 0.2
max_new_tokens = 300
device = mps
tokenization_method = custom_bpe
test_mode = True
vocab_size = 360

OUTPUT
======
üî¨ TEST MODE: Using reduced hyperparameters for fast training
‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)
Device: mps
Model size: 3 layers, 128 embedding dims, 4 heads
‚úÖ Custom BPE tokenizer trained (vocab_size=360)
Total model parameters: 694,632
Model device: mps:0
‚úÖ Model successfully moved to Apple Silicon GPU (MPS)
‚ÑπÔ∏è  Using MPS without compilation (torch.compile disabled for MPS)
Starting training for 1000 steps...
Batch size: 32, Block size: 64
Vocabulary size: 360 tokens
--------------------------------------------------
step 0/1000 (0.0%): train loss 6.0638, val loss 6.0451 | 0.9s (0.00 steps/sec)
step 25/1000 (2.5%) | 16.30 steps/sec | ETA: 1.0m
step 50/1000 (5.0%) | 24.66 steps/sec | ETA: 0.6m
step 75/1000 (7.5%) | 29.73 steps/sec | ETA: 0.5m
step 100/1000 (10.0%): train loss 5.0565, val loss 5.1347 | 3.6s (27.89 steps/sec)
step 125/1000 (12.5%) | 30.54 steps/sec | ETA: 0.5m
step 150/1000 (15.0%) | 32.69 steps/sec | ETA: 0.4m
step 175/1000 (17.5%) | 34.38 steps/sec | ETA: 0.4m
step 200/1000 (20.0%): train loss 4.4167, val loss 4.5754 | 6.2s (32.40 steps/sec)
step 225/1000 (22.5%) | 33.68 steps/sec | ETA: 0.4m
step 250/1000 (25.0%) | 34.85 steps/sec | ETA: 0.4m
step 275/1000 (27.5%) | 35.82 steps/sec | ETA: 0.3m
step 300/1000 (30.0%): train loss 4.0007, val loss 4.2761 | 8.7s (34.41 steps/sec)
step 325/1000 (32.5%) | 35.22 steps/sec | ETA: 0.3m
step 350/1000 (35.0%) | 35.99 steps/sec | ETA: 0.3m
step 375/1000 (37.5%) | 36.62 steps/sec | ETA: 0.3m
step 400/1000 (40.0%): train loss 3.7499, val loss 4.1492 | 11.3s (35.35 steps/sec)
step 425/1000 (42.5%) | 35.93 steps/sec | ETA: 0.3m
step 450/1000 (45.0%) | 36.50 steps/sec | ETA: 0.3m
step 475/1000 (47.5%) | 36.96 steps/sec | ETA: 0.2m
step 500/1000 (50.0%): train loss 3.6044, val loss 4.0782 | 14.0s (35.67 steps/sec)
step 525/1000 (52.5%) | 36.14 steps/sec | ETA: 0.2m
step 550/1000 (55.0%) | 36.58 steps/sec | ETA: 0.2m
step 575/1000 (57.5%) | 37.00 steps/sec | ETA: 0.2m
step 600/1000 (60.0%): train loss 3.4672, val loss 4.0740 | 16.6s (36.16 steps/sec)
step 625/1000 (62.5%) | 36.55 steps/sec | ETA: 0.2m
step 650/1000 (65.0%) | 36.95 steps/sec | ETA: 0.2m
step 675/1000 (67.5%) | 37.32 steps/sec | ETA: 0.1m
step 700/1000 (70.0%): train loss 3.3684, val loss 4.0413 | 19.1s (36.58 steps/sec)
step 725/1000 (72.5%) | 36.91 steps/sec | ETA: 0.1m
step 750/1000 (75.0%) | 37.24 steps/sec | ETA: 0.1m
step 775/1000 (77.5%) | 37.55 steps/sec | ETA: 0.1m
step 800/1000 (80.0%): train loss 3.2691, val loss 4.0734 | 21.7s (36.89 steps/sec)
step 825/1000 (82.5%) | 37.17 steps/sec | ETA: 0.1m
step 850/1000 (85.0%) | 37.46 steps/sec | ETA: 0.1m
step 875/1000 (87.5%) | 37.73 steps/sec | ETA: 0.1m
step 900/1000 (90.0%): train loss 3.1411, val loss 4.0351 | 24.2s (37.12 steps/sec)
step 925/1000 (92.5%) | 37.37 steps/sec | ETA: 0.0m
step 950/1000 (95.0%) | 37.63 steps/sec | ETA: 0.0m
step 975/1000 (97.5%) | 37.87 steps/sec | ETA: 0.0m
--------------------------------------------------
Training complete! Final loss: 3.1609
Total training time: 26.2s (38.10 steps/sec)

Generating text...
==================================================
x e with out li mo ve le . S y because t res at ment - re n es husband is sa me or n ' t to con re d to ge st about a be a r and $ up in the ir ad to o n ev ue and that ch an other p re st ) and . l it ( wh ic al our one y need to im es d ue in it was re ll h o c li w on g w are of op , but ha v i es k ion s and need ing . I s ! I sh o p s sa me es ri ght s , S ty and s , wh y no mo ve to b le ar ing , we e i z ed that be t ant ag es en se c ate ly go c us s it li ght ay , th ou th ou bi l ity to b work s n has as m un happ it s . Th en from my tr y for , th you ' s i th o you ' re me to ce he ' re I don ' t we want to do I f f act about p ts m un c . Th ate to p a st y that she ev ai l ink ent o se she want ing to ma ke h es . I me to re ct iv your g en . Th an who is w here , as on g iv ity to he ' s it is c ould k in in ter ms to s with some ght ed , but that for t that g ,
==================================================
